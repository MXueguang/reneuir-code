{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4c24188-1284-4a41-8901-ec98318bd4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['MKL_SERVICE_FORCE_INTEL'] = '1'\n",
    "os.environ['HF_HUB_OFFLINE'] = '1'\n",
    "\n",
    "from tira.third_party_integrations import ir_datasets, get_output_directory\n",
    "import numpy as np\n",
    "from colbert.infra import ColBERTConfig\n",
    "from colbert.data import Collection\n",
    "from colbert import Indexer\n",
    "import gzip\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff08774c-5f20-4293-a0e6-07e281c424cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ir_datasets.load('reneuir-2024/dl-top-10-docs-20240701-training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9fedaaa-2546-42aa-ab4b-c0e3cda586c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# was already compiled in the docker build, should be dast\n",
    "from colbert.indexing.codecs.residual import ResidualCodec\n",
    "ResidualCodec.try_load_torch_extensions(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "932a5045-c215-4cd7-bdc2-b382ea82855c",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = Collection.cast([ l.default_text() for l in dataset.docs_iter()])\n",
    "indexer = Indexer(checkpoint='hltcoe/plaidx-large-eng-tdist-mt5xxl-engeng', config=ColBERTConfig(bsize=64, nbits=1, root='/tmp/'))\n",
    "output_directory = get_output_directory('/tmp/') + '/index/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5b8ab3a-e47a-43ba-8df4-e9f12e5cc806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Indexing 6965 documents to \"/tmp//index/\".\n",
      "\n",
      "\n",
      "[Jul 05, 13:15:10] #> Creating directory /tmp//index/ \n",
      "\n",
      "\n",
      "#> Starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.\n",
      "\tTry to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nranks = 1 \t num_gpus = 4 \t device=0\n",
      "{\n",
      "    \"query_token_id\": \"[unused0]\",\n",
      "    \"doc_token_id\": \"[unused1]\",\n",
      "    \"query_token\": \"[Q]\",\n",
      "    \"doc_token\": \"[D]\",\n",
      "    \"ncells\": null,\n",
      "    \"centroid_score_threshold\": null,\n",
      "    \"ndocs\": null,\n",
      "    \"only_approx\": false,\n",
      "    \"index_path\": null,\n",
      "    \"nbits\": 1,\n",
      "    \"kmeans_niters\": 4,\n",
      "    \"resume\": false,\n",
      "    \"max_sampled_pid\": -1,\n",
      "    \"max_num_partitions\": -1,\n",
      "    \"use_lagacy_build_ivf\": false,\n",
      "    \"reuse_centroids_from\": null,\n",
      "    \"similarity\": \"cosine\",\n",
      "    \"bsize\": 64,\n",
      "    \"accumsteps\": 1,\n",
      "    \"lr\": 5e-6,\n",
      "    \"maxsteps\": 200000,\n",
      "    \"save_every\": null,\n",
      "    \"resume_optimizer\": false,\n",
      "    \"fix_broken_optimizer_state\": false,\n",
      "    \"warmup\": null,\n",
      "    \"warmup_bert\": null,\n",
      "    \"relu\": false,\n",
      "    \"nway\": 6,\n",
      "    \"n_query_alternative\": 1,\n",
      "    \"use_ib_negatives\": false,\n",
      "    \"kd_loss\": \"KLD\",\n",
      "    \"reranker\": false,\n",
      "    \"distillation_alpha\": 1.0,\n",
      "    \"ignore_scores\": false,\n",
      "    \"model_name\": \"xlm-roberta-large\",\n",
      "    \"force_resize_embeddings\": true,\n",
      "    \"shuffle_passages\": true,\n",
      "    \"sampling_max_beta\": 1.0,\n",
      "    \"over_one_epoch\": true,\n",
      "    \"multilang\": false,\n",
      "    \"nolangreg\": false,\n",
      "    \"query_maxlen\": 32,\n",
      "    \"attend_to_mask_tokens\": false,\n",
      "    \"interaction\": \"colbert\",\n",
      "    \"dim\": 128,\n",
      "    \"doc_maxlen\": 220,\n",
      "    \"mask_punctuation\": true,\n",
      "    \"checkpoint\": \"hltcoe\\/plaidx-large-eng-tdist-mt5xxl-engeng\",\n",
      "    \"triples\": \"\\/expscratch\\/eyang\\/workspace\\/plaid-aux\\/training_triples\\/msmarco-passages\\/triples_mt5xxl-monot5-mmarco-engeng.jsonl\",\n",
      "    \"collection\": {\n",
      "        \"provenance\": null\n",
      "    },\n",
      "    \"queries\": \"irds:msmarco-passage\\/train:queries\",\n",
      "    \"index_name\": \"\\/tmp\\/\\/index\\/\",\n",
      "    \"debug\": false,\n",
      "    \"overwrite\": false,\n",
      "    \"root\": \"\\/workspace\\/experiments\",\n",
      "    \"experiment\": \"default\",\n",
      "    \"index_root\": null,\n",
      "    \"name\": \"2024-07\\/05\\/13.14.56\",\n",
      "    \"rank\": 0,\n",
      "    \"nranks\": 1,\n",
      "    \"amp\": true,\n",
      "    \"ivf_num_processes\": 20,\n",
      "    \"ivf_use_tempdir\": false,\n",
      "    \"ivf_merging_ways\": 2,\n",
      "    \"gpus\": 4\n",
      "}\n",
      "[Jul 05, 13:15:13] [0] \t\t Loading model hltcoe/plaidx-large-eng-tdist-mt5xxl-engeng...\n",
      "[Jul 05, 13:15:23] [0] \t\t # of sampled PIDs = 6965 \t sampled_pids[:3] = [3412, 6002, 83]\n",
      "[Jul 05, 13:15:23] [0] \t\t #> Encoding 6965 passages..\n",
      "[Jul 05, 13:15:57] [0] \t\t avg_doclen_est = 90.55908203125 \t len(local_sample) = 6,965\n",
      "[Jul 05, 13:15:58] [0] \t\t Creaing 8,192 partitions.\n",
      "[Jul 05, 13:15:58] [0] \t\t *Estimated* 630,744 embeddings.\n",
      "[Jul 05, 13:15:58] [0] \t\t #> Saving the indexing plan to /tmp//index/plan.json ..\n",
      "#> Joined...\n",
      "{\n",
      "    \"query_token_id\": \"[unused0]\",\n",
      "    \"doc_token_id\": \"[unused1]\",\n",
      "    \"query_token\": \"[Q]\",\n",
      "    \"doc_token\": \"[D]\",\n",
      "    \"ncells\": null,\n",
      "    \"centroid_score_threshold\": null,\n",
      "    \"ndocs\": null,\n",
      "    \"only_approx\": false,\n",
      "    \"index_path\": null,\n",
      "    \"nbits\": 1,\n",
      "    \"kmeans_niters\": 4,\n",
      "    \"resume\": false,\n",
      "    \"max_sampled_pid\": -1,\n",
      "    \"max_num_partitions\": -1,\n",
      "    \"use_lagacy_build_ivf\": false,\n",
      "    \"reuse_centroids_from\": null,\n",
      "    \"similarity\": \"cosine\",\n",
      "    \"bsize\": 64,\n",
      "    \"accumsteps\": 1,\n",
      "    \"lr\": 5e-6,\n",
      "    \"maxsteps\": 200000,\n",
      "    \"save_every\": null,\n",
      "    \"resume_optimizer\": false,\n",
      "    \"fix_broken_optimizer_state\": false,\n",
      "    \"warmup\": null,\n",
      "    \"warmup_bert\": null,\n",
      "    \"relu\": false,\n",
      "    \"nway\": 6,\n",
      "    \"n_query_alternative\": 1,\n",
      "    \"use_ib_negatives\": false,\n",
      "    \"kd_loss\": \"KLD\",\n",
      "    \"reranker\": false,\n",
      "    \"distillation_alpha\": 1.0,\n",
      "    \"ignore_scores\": false,\n",
      "    \"model_name\": \"xlm-roberta-large\",\n",
      "    \"force_resize_embeddings\": true,\n",
      "    \"shuffle_passages\": true,\n",
      "    \"sampling_max_beta\": 1.0,\n",
      "    \"over_one_epoch\": true,\n",
      "    \"multilang\": false,\n",
      "    \"nolangreg\": false,\n",
      "    \"query_maxlen\": 32,\n",
      "    \"attend_to_mask_tokens\": false,\n",
      "    \"interaction\": \"colbert\",\n",
      "    \"dim\": 128,\n",
      "    \"doc_maxlen\": 220,\n",
      "    \"mask_punctuation\": true,\n",
      "    \"checkpoint\": \"hltcoe\\/plaidx-large-eng-tdist-mt5xxl-engeng\",\n",
      "    \"triples\": \"\\/expscratch\\/eyang\\/workspace\\/plaid-aux\\/training_triples\\/msmarco-passages\\/triples_mt5xxl-monot5-mmarco-engeng.jsonl\",\n",
      "    \"collection\": {\n",
      "        \"provenance\": null\n",
      "    },\n",
      "    \"queries\": \"irds:msmarco-passage\\/train:queries\",\n",
      "    \"index_name\": \"\\/tmp\\/\\/index\\/\",\n",
      "    \"debug\": false,\n",
      "    \"overwrite\": false,\n",
      "    \"root\": \"\\/workspace\\/experiments\",\n",
      "    \"experiment\": \"default\",\n",
      "    \"index_root\": null,\n",
      "    \"name\": \"2024-07\\/05\\/13.14.56\",\n",
      "    \"rank\": 0,\n",
      "    \"nranks\": 1,\n",
      "    \"amp\": true,\n",
      "    \"ivf_num_processes\": 20,\n",
      "    \"ivf_use_tempdir\": false,\n",
      "    \"ivf_merging_ways\": 2,\n",
      "    \"gpus\": 4\n",
      "}\n",
      "[Jul 05, 13:16:00] Loading 1 sample embedding files, expecting 630744 samples\n",
      "Clustering 599207 points in 128D to 8192 clusters, redo 1 times, 4 iterations\n",
      "  Preprocessing in 0.05 s\n",
      "[0.031, 0.029, 0.031, 0.029, 0.029, 0.028, 0.029, 0.029, 0.028, 0.027, 0.026, 0.032, 0.028, 0.03, 0.029, 0.028, 0.029, 0.027, 0.029, 0.026, 0.029, 0.031, 0.029, 0.029, 0.03, 0.031, 0.031, 0.029, 0.029, 0.029, 0.03, 0.027, 0.03, 0.027, 0.029, 0.031, 0.028, 0.029, 0.03, 0.029, 0.029, 0.032, 0.027, 0.029, 0.027, 0.028, 0.03, 0.032, 0.029, 0.03, 0.027, 0.028, 0.031, 0.029, 0.027, 0.029, 0.028, 0.03, 0.03, 0.027, 0.027, 0.027, 0.03, 0.031, 0.029, 0.026, 0.028, 0.029, 0.03, 0.031, 0.026, 0.029, 0.031, 0.029, 0.03, 0.033, 0.029, 0.026, 0.026, 0.032, 0.031, 0.03, 0.028, 0.029, 0.028, 0.028, 0.034, 0.03, 0.028, 0.033, 0.026, 0.029, 0.028, 0.031, 0.027, 0.03, 0.029, 0.029, 0.031, 0.029, 0.029, 0.03, 0.028, 0.033, 0.027, 0.03, 0.03, 0.03, 0.031, 0.029, 0.027, 0.029, 0.031, 0.029, 0.027, 0.03, 0.032, 0.028, 0.032, 0.03, 0.031, 0.03, 0.029, 0.031, 0.028, 0.028, 0.029, 0.031]\n",
      "[Jul 05, 13:16:04] #> Got bucket_cutoffs_quantiles = tensor([0.5000], device='cuda:0') and bucket_weights_quantiles = tensor([0.2500, 0.7500], device='cuda:0')\n",
      "[Jul 05, 13:16:04] #> Got bucket_cutoffs = tensor([0.], device='cuda:0') and bucket_weights = tensor([-0.0201,  0.0202], device='cuda:0')\n",
      "[Jul 05, 13:16:04] avg_residual = 0.029208917170763016\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/tmp//index/'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Start Indexing {len(collection)} documents to \"{output_directory}\".')\n",
    "\n",
    "indexer.prepare(name=output_directory, collection=collection, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9d8b353-53d9-492f-b50f-ffb105217061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#> Starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.\n",
      "\tTry to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nranks = 1 \t num_gpus = 4 \t device=0\n",
      "{\n",
      "    \"query_token_id\": \"[unused0]\",\n",
      "    \"doc_token_id\": \"[unused1]\",\n",
      "    \"query_token\": \"[Q]\",\n",
      "    \"doc_token\": \"[D]\",\n",
      "    \"ncells\": null,\n",
      "    \"centroid_score_threshold\": null,\n",
      "    \"ndocs\": null,\n",
      "    \"only_approx\": false,\n",
      "    \"index_path\": null,\n",
      "    \"nbits\": 1,\n",
      "    \"kmeans_niters\": 4,\n",
      "    \"resume\": true,\n",
      "    \"max_sampled_pid\": -1,\n",
      "    \"max_num_partitions\": -1,\n",
      "    \"use_lagacy_build_ivf\": false,\n",
      "    \"reuse_centroids_from\": null,\n",
      "    \"similarity\": \"cosine\",\n",
      "    \"bsize\": 64,\n",
      "    \"accumsteps\": 1,\n",
      "    \"lr\": 5e-6,\n",
      "    \"maxsteps\": 200000,\n",
      "    \"save_every\": null,\n",
      "    \"resume_optimizer\": false,\n",
      "    \"fix_broken_optimizer_state\": false,\n",
      "    \"warmup\": null,\n",
      "    \"warmup_bert\": null,\n",
      "    \"relu\": false,\n",
      "    \"nway\": 6,\n",
      "    \"n_query_alternative\": 1,\n",
      "    \"use_ib_negatives\": false,\n",
      "    \"kd_loss\": \"KLD\",\n",
      "    \"reranker\": false,\n",
      "    \"distillation_alpha\": 1.0,\n",
      "    \"ignore_scores\": false,\n",
      "    \"model_name\": \"xlm-roberta-large\",\n",
      "    \"force_resize_embeddings\": true,\n",
      "    \"shuffle_passages\": true,\n",
      "    \"sampling_max_beta\": 1.0,\n",
      "    \"over_one_epoch\": true,\n",
      "    \"multilang\": false,\n",
      "    \"nolangreg\": false,\n",
      "    \"query_maxlen\": 32,\n",
      "    \"attend_to_mask_tokens\": false,\n",
      "    \"interaction\": \"colbert\",\n",
      "    \"dim\": 128,\n",
      "    \"doc_maxlen\": 220,\n",
      "    \"mask_punctuation\": true,\n",
      "    \"checkpoint\": \"hltcoe\\/plaidx-large-eng-tdist-mt5xxl-engeng\",\n",
      "    \"triples\": \"\\/expscratch\\/eyang\\/workspace\\/plaid-aux\\/training_triples\\/msmarco-passages\\/triples_mt5xxl-monot5-mmarco-engeng.jsonl\",\n",
      "    \"collection\": {\n",
      "        \"provenance\": null\n",
      "    },\n",
      "    \"queries\": \"irds:msmarco-passage\\/train:queries\",\n",
      "    \"index_name\": \"\\/tmp\\/\\/index\\/\",\n",
      "    \"debug\": false,\n",
      "    \"overwrite\": false,\n",
      "    \"root\": \"\\/workspace\\/experiments\",\n",
      "    \"experiment\": \"default\",\n",
      "    \"index_root\": null,\n",
      "    \"name\": \"2024-07\\/05\\/13.14.56\",\n",
      "    \"rank\": 0,\n",
      "    \"nranks\": 1,\n",
      "    \"amp\": true,\n",
      "    \"ivf_num_processes\": 20,\n",
      "    \"ivf_use_tempdir\": false,\n",
      "    \"ivf_merging_ways\": 2,\n",
      "    \"gpus\": 4\n",
      "}\n",
      "[Jul 05, 13:16:13] [0] \t\t Loading model hltcoe/plaidx-large-eng-tdist-mt5xxl-engeng...\n",
      "[Jul 05, 13:16:21] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[Jul 05, 13:16:21] Loading packbits_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/cpp_extension.py:1967: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 05, 13:16:21] [0] \t\t #> Encoding 6965 passages..\n",
      "[Jul 05, 13:16:55] [0] \t\t #> Saving chunk 0: \t 6,965 passages and 630,744 embeddings. From #0 onward.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:33, 33.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#> Joined...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/tmp//index/'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexer.encode(name=output_directory, collection=collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "281a08a0-de0d-4082-b909-7e9af71e3ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"query_token_id\": \"[unused0]\",\n",
      "    \"doc_token_id\": \"[unused1]\",\n",
      "    \"query_token\": \"[Q]\",\n",
      "    \"doc_token\": \"[D]\",\n",
      "    \"ncells\": null,\n",
      "    \"centroid_score_threshold\": null,\n",
      "    \"ndocs\": null,\n",
      "    \"only_approx\": false,\n",
      "    \"index_path\": null,\n",
      "    \"nbits\": 1,\n",
      "    \"kmeans_niters\": 4,\n",
      "    \"resume\": true,\n",
      "    \"max_sampled_pid\": -1,\n",
      "    \"max_num_partitions\": -1,\n",
      "    \"use_lagacy_build_ivf\": false,\n",
      "    \"reuse_centroids_from\": null,\n",
      "    \"similarity\": \"cosine\",\n",
      "    \"bsize\": 64,\n",
      "    \"accumsteps\": 1,\n",
      "    \"lr\": 5e-6,\n",
      "    \"maxsteps\": 200000,\n",
      "    \"save_every\": null,\n",
      "    \"resume_optimizer\": false,\n",
      "    \"fix_broken_optimizer_state\": false,\n",
      "    \"warmup\": null,\n",
      "    \"warmup_bert\": null,\n",
      "    \"relu\": false,\n",
      "    \"nway\": 6,\n",
      "    \"n_query_alternative\": 1,\n",
      "    \"use_ib_negatives\": false,\n",
      "    \"kd_loss\": \"KLD\",\n",
      "    \"reranker\": false,\n",
      "    \"distillation_alpha\": 1.0,\n",
      "    \"ignore_scores\": false,\n",
      "    \"model_name\": \"xlm-roberta-large\",\n",
      "    \"force_resize_embeddings\": true,\n",
      "    \"shuffle_passages\": true,\n",
      "    \"sampling_max_beta\": 1.0,\n",
      "    \"over_one_epoch\": true,\n",
      "    \"multilang\": false,\n",
      "    \"nolangreg\": false,\n",
      "    \"query_maxlen\": 32,\n",
      "    \"attend_to_mask_tokens\": false,\n",
      "    \"interaction\": \"colbert\",\n",
      "    \"dim\": 128,\n",
      "    \"doc_maxlen\": 220,\n",
      "    \"mask_punctuation\": true,\n",
      "    \"checkpoint\": \"hltcoe\\/plaidx-large-eng-tdist-mt5xxl-engeng\",\n",
      "    \"triples\": \"\\/expscratch\\/eyang\\/workspace\\/plaid-aux\\/training_triples\\/msmarco-passages\\/triples_mt5xxl-monot5-mmarco-engeng.jsonl\",\n",
      "    \"collection\": {\n",
      "        \"provenance\": null\n",
      "    },\n",
      "    \"queries\": \"irds:msmarco-passage\\/train:queries\",\n",
      "    \"index_name\": \"\\/tmp\\/\\/index\\/\",\n",
      "    \"debug\": false,\n",
      "    \"overwrite\": false,\n",
      "    \"root\": \"\\/workspace\\/experiments\",\n",
      "    \"experiment\": \"default\",\n",
      "    \"index_root\": null,\n",
      "    \"name\": \"2024-07\\/05\\/12.34.56\",\n",
      "    \"rank\": 0,\n",
      "    \"nranks\": 1,\n",
      "    \"amp\": true,\n",
      "    \"ivf_num_processes\": 20,\n",
      "    \"ivf_use_tempdir\": false,\n",
      "    \"ivf_merging_ways\": 2,\n",
      "    \"gpus\": 1\n",
      "}\n",
      "[Jul 05, 12:37:50] [0] \t\t Loading model hltcoe/plaidx-large-eng-tdist-mt5xxl-engeng...\n",
      "[Jul 05, 12:37:58] [0] \t\t #> Checking all files were saved, expecting 1...\n",
      "[Jul 05, 12:37:58] [0] \t\t Found all files!\n",
      "[Jul 05, 12:37:58] [0] \t\t #> Read file: `/tmp//index/0.metadata.json`\n",
      "[Jul 05, 12:37:58] [0] \t\t #> Building IVF...\n",
      "[Jul 05, 12:37:58] [0] \t\t #> Building local IVFs with 20 processes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.\n",
      "\tTry to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 05, 12:38:06] [0] \t\t #> Chunk 0 done\n",
      "[Jul 05, 12:38:06] [0] \t\t 2-way merging, expecting 0 iterations\n",
      "[Jul 05, 12:38:06] [0] \t\t Read final IVF file\n",
      "[Jul 05, 12:38:06] [0] \t\t #> Creating ivf tensor...\n",
      "[Jul 05, 12:38:06] #> Saved optimized IVF to /tmp//index/ivf.pid.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "clean up local ivf files: 100%|███████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 3368.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jul 05, 12:38:06] [0] \t\t #> Saving the indexing metadata to /tmp//index/metadata.json ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/tmp//index/'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexer.finalize(name=output_directory, collection=collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "945bafab-7d08-4adc-8535-fcc2bff6d928",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_ids = [ l.doc_id for l in dataset.docs_iter()]\n",
    "json.dump(doc_ids, gzip.open(f'{output_directory}/document_ids.json.gz', 'wt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56d5997a-ed6f-4879-bca6-df530c425123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done:\n",
      "total 169M\n",
      "drwxr-xr-x 1 root root  260 Jul  5 13:17 .\n",
      "drwxrwxrwt 1 root root   36 Jul  5 13:16 ..\n",
      "-rw-r--r-- 1 root root 2.5M Jul  5 13:16 0.codes.pt\n",
      "-rw-r--r-- 1 root root   64 Jul  5 13:16 0.metadata.json\n",
      "-rw-r--r-- 1 root root 9.7M Jul  5 13:16 0.residuals.pt\n",
      "-rw-r--r-- 1 root root 1.2K Jul  5 13:16 avg_residual.pt\n",
      "-rw-r--r-- 1 root root 1.4K Jul  5 13:16 buckets.pt\n",
      "-rw-r--r-- 1 root root 2.1M Jul  5 13:16 centroids.pt\n",
      "-rw-r--r-- 1 root root  23K Jul  5 13:16 doclens.0.json\n",
      "-rw-r--r-- 1 root root  28K Jul  5 13:17 document_ids.json.gz\n",
      "-rw-r--r-- 1 root root 2.3K Jul  5 13:15 plan.json\n",
      "-rw-r--r-- 1 root root 154M Jul  5 13:15 sample.0.pt\n"
     ]
    }
   ],
   "source": [
    "print('Done:')\n",
    "!ls -lha {output_directory}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
